{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import uproot\n",
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "import sys\n",
    "import shutil\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "sys.path += [\"../hepaccelerate\"]\n",
    "import hepaccelerate\n",
    "\n",
    "from dask.distributed import Client, get_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = Client()\n",
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed.diagnostics.plugin import WorkerPlugin\n",
    "\n",
    "class SandboxPlugin(WorkerPlugin):\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "    \n",
    "    def setup(self, worker):\n",
    "        self.worker = worker\n",
    "        \n",
    "        #os.chdir(worker.local_directory)\n",
    "        \n",
    "        os.system(\"tar xf sandbox.tgz\")\n",
    "        os.chdir(\"hepaccelerate-cms\")\n",
    "        if not \"./hepaccelerate\" in sys.path:\n",
    "            sys.path += [\"./hepaccelerate\", \"./coffea\"]\n",
    "        \n",
    "    def transition(self, key, start, finish, *args, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "\n",
    "credentials = session.get_credentials()\n",
    "access_key = credentials.access_key\n",
    "secret_key = credentials.secret_key\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = access_key\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = secret_key\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"/home/jovyan/sandbox.tgz\")\n",
    "cwd = os.getcwd()\n",
    "os.chdir(\"/home/jovyan\")\n",
    "os.system(\"tar -czf sandbox.tgz hepaccelerate-cms\")\n",
    "os.chdir(cwd)\n",
    "plugin = SandboxPlugin(os.environ)\n",
    "cl.restart(timeout=120)\n",
    "cl.upload_file(\"/home/jovyan/sandbox.tgz\")\n",
    "cl.register_worker_plugin(plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(\n",
    "    \"hepaccelerate-hmm-skim-merged\",\n",
    "    \"files.txt\",\n",
    "    \"files.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = [f.strip() for f in open(\"files.txt\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_events(fn, env=os.environ):\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=env[\"AWS_ACCESS_KEY_ID\"],\n",
    "        aws_secret_access_key=env[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    )\n",
    "    \n",
    "    t0 = time.time()\n",
    "    tmp = tempfile.mktemp()\n",
    "    s3.download_file(\n",
    "        \"hepaccelerate-hmm-skim-merged\",\n",
    "        fn[1:],\n",
    "        tmp\n",
    "    )\n",
    "    tf = uproot.open(tmp)\n",
    "    tt = tf.get(\"Events\")\n",
    "    nev = len(tt)\n",
    "    file_size = os.path.getsize(tmp)\n",
    "    os.remove(tmp)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    ret = {\n",
    "        \"num_events\": nev,\n",
    "        \"file_size\": file_size,\n",
    "        \"time_delta\": t1 - t0,\n",
    "        \"t1\": t1,\n",
    "        \"t0\": t0,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = cl.map(get_num_events, fl[:10])\n",
    "progress(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets2 = [r.result() for r in rets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(rets):\n",
    "    total_size = sum([r[\"file_size\"] for r in rets])\n",
    "    start_time = min([r[\"t0\"] for r in rets])\n",
    "    end_time = max([r[\"t1\"] for r in rets])\n",
    "    return {\n",
    "        \"total_size\": total_size,\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": end_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = aggregate(rets2)\n",
    "agg[\"total_size\"] / (agg[\"end_time\"] - agg[\"start_time\"]) / 1000 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sandbox(args, env=os.environ):\n",
    "    fn, dataset_name, dataset_era, is_mc, num_chunk, random_seed = args\n",
    "    \n",
    "    worker = get_worker()\n",
    "\n",
    "    tmproot = tempfile.mktemp(suffix=\".root\")\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=env[\"AWS_ACCESS_KEY_ID\"],\n",
    "        aws_secret_access_key=env[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    )\n",
    "    s3.download_file(\n",
    "        \"hepaccelerate-hmm-skim-merged\",\n",
    "        fn[1:],\n",
    "        tmproot\n",
    "    )\n",
    "    \n",
    "    job_descriptions = [\n",
    "        {\n",
    "            \"dataset_name\": dataset_name,\n",
    "            \"dataset_era\": dataset_era,\n",
    "            \"filenames\": [tmproot],\n",
    "            \"is_mc\": is_mc,\n",
    "            \"dataset_num_chunk\": num_chunk,\n",
    "            \"random_seed\": random_seed\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    tmpout = tempfile.mkdtemp(suffix=\"_out\")\n",
    "    tmpjson = tempfile.mktemp(suffix=\".json\")\n",
    "    with open(tmpjson, \"w\") as fi:\n",
    "        json.dump(job_descriptions, fi)\n",
    "    \n",
    "    os.system(\"PYTHONPATH=hepaccelerate:coffea:. python tests/hmm/run_jd.py {0} {1}\".format(tmpjson, tmpout))\n",
    "    \n",
    "    ret = pickle.load(open(tmpout + \"/{0}_{1}_{2}.pkl\".format(dataset_name, dataset_era, num_chunk), \"rb\"))\n",
    "    os.remove(tmproot)\n",
    "    os.remove(tmpjson)\n",
    "    shutil.rmtree(tmpout)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = []\n",
    "\n",
    "i = 0\n",
    "for fn in fl[:10]:\n",
    "    args += [(fn, \"dy_0j\", \"2016\", True, i, i)]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futs = cl.map(check_sandbox, args, retries=0)\n",
    "rets = [f.result() for f in futs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
